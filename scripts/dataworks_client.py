# -*- coding: utf-8 -*-
"""
dataworks_client.py
èŒè´£ï¼šå°è£…é˜¿é‡Œäº‘ DataWorks API çš„è°ƒç”¨é€»è¾‘ã€‚

å¯¹å¤–æä¾›äº”ä¸ªå‡½æ•°ï¼š
  - create_client()  : åˆå§‹åŒ– DataWorks SDK å®¢æˆ·ç«¯
  - build_spec()     : æŠŠ task-config.json çš„é…ç½®è½¬æ¢æˆ DataWorks èŠ‚ç‚¹æ‰€éœ€çš„ JSON æ ¼å¼
  - create_node()    : è°ƒç”¨ DataWorks API åˆ›å»ºå®šæ—¶åŒæ­¥èŠ‚ç‚¹
  - get_node_id()    : é€šè¿‡èŠ‚ç‚¹åç²¾ç¡®æŸ¥æ‰¾èŠ‚ç‚¹ï¼Œè¿”å› Data Studio èŠ‚ç‚¹ ID
  - update_node()    : è°ƒç”¨ DataWorks API å¢é‡æ›´æ–°å·²æœ‰èŠ‚ç‚¹
"""

import json
import os
import sys

# DataWorks å®˜æ–¹ Python SDKï¼ˆ2024-05-18 ç‰ˆæœ¬ï¼‰
from alibabacloud_dataworks_public20240518.client import Client as DataWorksPublicClient
# SDK é€šç”¨é…ç½®ï¼ˆendpointã€AK ç­‰ï¼‰
from alibabacloud_tea_openapi import models as open_api_models
# DataWorks è¯·æ±‚/å“åº”æ¨¡å‹
from alibabacloud_dataworks_public20240518 import models as dw_models
# SDK è¿è¡Œæ—¶å‚æ•°ï¼ˆè¶…æ—¶ã€é‡è¯•ç­‰ï¼‰
from alibabacloud_tea_util import models as util_models


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å‡½æ•°ä¸€ï¼šåˆå§‹åŒ– DataWorks å®¢æˆ·ç«¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_client() -> DataWorksPublicClient:
    """
    ä»ç¯å¢ƒå˜é‡è¯»å–è®¿é—®å‡­è¯ï¼Œåˆå§‹åŒ–å¹¶è¿”å› DataWorks SDK å®¢æˆ·ç«¯ã€‚

    æ‰€éœ€ç¯å¢ƒå˜é‡ï¼ˆåœ¨ GitHub Actions ä¸­é€šè¿‡ secrets æ³¨å…¥ï¼‰ï¼š
      ALIBABA_CLOUD_ACCESS_KEY_ID      : é˜¿é‡Œäº‘ AccessKey ID
      ALIBABA_CLOUD_ACCESS_KEY_SECRET  : é˜¿é‡Œäº‘ AccessKey Secret
      ALIYUN_REGION                    : é˜¿é‡Œäº‘åœ°åŸŸï¼ˆå¦‚ cn-shanghaiï¼‰
    """
    access_key_id     = os.environ.get("ALIBABA_CLOUD_ACCESS_KEY_ID", "")
    access_key_secret = os.environ.get("ALIBABA_CLOUD_ACCESS_KEY_SECRET", "")
    region            = os.environ.get("ALIYUN_REGION", "cn-shanghai")

    # å¦‚æœå‡­è¯ä¸ºç©ºï¼Œç«‹å³æŠ¥é”™é€€å‡ºï¼Œé¿å…åç»­è°ƒç”¨æŠ¥å¥‡æ€ªçš„é”™è¯¯
    if not access_key_id or not access_key_secret:
        print("ERROR: ALIBABA_CLOUD_ACCESS_KEY_ID / ALIBABA_CLOUD_ACCESS_KEY_SECRET not set")
        sys.exit(1)

    # æ„å»º SDK é…ç½®å¯¹è±¡
    config = open_api_models.Config(
        access_key_id=access_key_id,
        access_key_secret=access_key_secret,
    )
    # DataWorks çš„ API åœ°å€æ ¼å¼å›ºå®šä¸ºï¼šdataworks.<region>.aliyuncs.com
    config.endpoint = f"dataworks.{region}.aliyuncs.com"

    return DataWorksPublicClient(config)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å‡½æ•°äºŒï¼šæ„å»º CreateNode æ‰€éœ€çš„ spec JSON
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_spec(config: dict) -> str:
    """
    æŠŠ config.json çš„é…ç½®è½¬æ¢æˆ DataWorks CreateNode API æ‰€è¦æ±‚çš„ spec JSON å­—ç¬¦ä¸²ã€‚

    DataWorks CreateNode çš„ spec æ˜¯ä¸¤å±‚åµŒå¥— JSONï¼š
      å¤–å±‚ï¼ˆspec_dictï¼‰ï¼šæè¿°èŠ‚ç‚¹è°ƒåº¦é…ç½®ï¼ˆå®šæ—¶ã€é‡è·‘ç­–ç•¥ç­‰ï¼‰
      å†…å±‚ï¼ˆdi_job_contentï¼‰ï¼šæè¿°æ•°æ®é›†æˆä»»åŠ¡ï¼ˆè¯»å“ªé‡Œã€å†™å“ªé‡Œï¼‰

    Args:
        config: ä» config.json è¯»å–çš„å­—å…¸
    Returns:
        spec_json: JSON å­—ç¬¦ä¸²ï¼Œç›´æ¥ä¼ ç»™ CreateNodeRequest.spec
    """
    resource_group = config.get("resource_group", "")

    # â”€â”€ å†…å±‚ï¼šæ•°æ®é›†æˆä»»åŠ¡é…ç½®ï¼ˆdi_job_contentï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    di_job_content = {
        "extend": {
            "mode": "wizard",
            "resourceGroup": resource_group,
            "oneStopPageNum": config.get("oneStopPageNum", 2),
            "cu": config.get("cu", 0.5)
        },
        "transform": config.get("transform", False),
        "type": "job",
        "version": "2.0",
        "steps": [
            {
                "stepType": "oss",
                "copies": 1,
                "parameter": {
                    "path":       config.get("reader", {}).get("path", ""),
                    "envType":    config.get("reader", {}).get("envType", 1),
                    "datasource": config.get("reader", {}).get("datasource", ""),
                    "column":     config.get("reader", {}).get("column", []),
                    "fileFormat": config.get("reader", {}).get("fileFormat", "parquet")
                },
                "name": "Reader",
                "category": "reader"
            },
            {
                "stepType": "odps",
                "copies": 1,
                "parameter": {
                    "partition":         config.get("writer", {}).get("partition", ""),
                    "truncate":          config.get("writer", {}).get("truncate", False),
                    "envType":           config.get("writer", {}).get("envType", 1),
                    "datasource":        config.get("writer", {}).get("datasource", ""),
                    "isSupportThreeModel": config.get("writer", {}).get("isSupportThreeModel", False),
                    "tunnelQuota":       config.get("writer", {}).get("tunnelQuota", "default"),
                    "column":            config.get("writer", {}).get("column", []),
                    "emptyAsNull":       config.get("writer", {}).get("emptyAsNull", False),
                    "tableComment":      config.get("writer", {}).get("tableComment", "null"),
                    "consistencyCommit": config.get("writer", {}).get("consistencyCommit", True),
                    "table":             config.get("writer", {}).get("table", "")
                },
                "name": "Writer",
                "category": "writer"
            }
        ],
        "order": {
            "hops": config.get("hops", [])
        },
        "setting": {
            "errorLimit": {"record": "0"},
            "locale": "zh_CN",
            "speed": {"throttle": False, "concurrent": 1}
        }
    }

    # â”€â”€ å¤–å±‚ï¼šDataWorks èŠ‚ç‚¹è°ƒåº¦é…ç½®ï¼ˆspec_dictï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    node_name = config.get("node_name", "")
    
    script_content = {
        "path": node_name,
        "language": "json",
        "runtime": {
            "command": "DI",
            "commandTypeId": config.get("script_commandTypeId", 23),
            "cu": str(config.get("script_cu", "0.25"))
        },
        "content": json.dumps(di_job_content, ensure_ascii=False)
    }
    
    if "parameters" in config:
        script_content["parameters"] = config["parameters"]

    trigger_config = {
        "type": "Scheduler",
        "cron": config.get("cron", "00 00 00-23/1 * * ?"),
        "startTime": config.get("startTime", "1970-01-01 00:00:00"),
        "endTime": config.get("endTime", "9999-01-01 00:00:00"),
        "timezone": config.get("timezone", "Asia/Shanghai"),
        "delaySeconds": config.get("delaySeconds", 0)
    }
    if "cycleType" in config:
        trigger_config["cycleType"] = config["cycleType"]

    runtime_resource = {
        "resourceGroup": resource_group
    }
    if "resourceGroupId" in config:
        runtime_resource["resourceGroupId"] = config["resourceGroupId"]
    if "resourceGroupName" in config:
        runtime_resource["resourceGroupName"] = config["resourceGroupName"]

    node_def = {
        "recurrence": "Normal",
        "maxInternalConcurrency": config.get("maxInternalConcurrency", 0),
        "timeout": config.get("timeout", 0),
        "timeoutUnit": config.get("timeoutUnit", "HOURS"),
        "instanceMode": config.get("instanceMode", "Immediately"),
        "rerunMode": config.get("rerunMode", "Allowed"),
        "rerunTimes": config.get("rerunTimes", 0),
        "rerunInterval": config.get("rerunInterval", 180000),
        "autoParse": config.get("autoParse", False),
        "script": script_content,
        "trigger": trigger_config,
        "runtimeResource": runtime_resource,
        "name": node_name,
        "owner": config.get("owner", "")
    }
    
    if "metadata" in config:
        node_def["metadata"] = config["metadata"]

    spec_dict = {
        "version": "1.1.0",
        "kind": "CycleWorkflow",
        "spec": {
            "nodes": [node_def],
            "flow": [{"depends": config.get("depends", [])}] if config.get("depends") else []
        }
    }

    # è¿”å›æœ€ç»ˆ JSON å­—ç¬¦ä¸²ï¼ˆensure_ascii=False ä¿ç•™ä¸­æ–‡å­—ç¬¦ï¼‰
    return json.dumps(spec_dict, ensure_ascii=False)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å‡½æ•°ä¸‰ï¼šè°ƒç”¨ DataWorks API åˆ›å»ºèŠ‚ç‚¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_node(client: DataWorksPublicClient, config: dict, project_id: int) -> None:
    """
    è°ƒç”¨ DataWorks CreateNode APIï¼Œåœ¨æŒ‡å®šå·¥ä½œç©ºé—´ä¸­åˆ›å»ºå®šæ—¶æ•°æ®åŒæ­¥èŠ‚ç‚¹ã€‚

    Args:
        client:     ç”± create_client() è¿”å›çš„ SDK å®¢æˆ·ç«¯
        config:     ç”± config.json è¯»å–çš„é…ç½®å­—å…¸
        project_id: DataWorks å·¥ä½œç©ºé—´ IDï¼ˆå¯¹åº”ç¯å¢ƒå˜é‡ DATAWORKS_PROJECT_IDï¼‰
    """
    # ç¬¬ä¸€æ­¥ï¼šæŠŠé…ç½®è½¬æ¢æˆ spec JSON å­—ç¬¦ä¸²
    spec_json = build_spec(config)

    # ç¬¬äºŒæ­¥ï¼šæ„å»º API è¯·æ±‚å¯¹è±¡
    create_node_request = dw_models.CreateNodeRequest(
        project_id=project_id,          # DataWorks å·¥ä½œç©ºé—´ ID
        spec=spec_json,                  # ä¸Šé¢ç”Ÿæˆçš„èŠ‚ç‚¹è§„æ ¼ JSON
        scene="DATAWORKS_PROJECT"        # å›ºå®šå€¼ï¼šåœ¨ DataWorks é¡¹ç›®ä¸­åˆ›å»º
    )
    runtime = util_models.RuntimeOptions()   # ä½¿ç”¨é»˜è®¤è¿è¡Œæ—¶å‚æ•°ï¼ˆè¶…æ—¶ã€é‡è¯•ï¼‰

    # ç¬¬ä¸‰æ­¥ï¼šè°ƒç”¨ API
    try:
        resp = client.create_node_with_options(create_node_request, runtime)
        # æˆåŠŸï¼šæ‰“å°è¿”å›ç»“æœï¼ˆåŒ…å« NodeIdï¼‰
        print(json.dumps(resp.body.to_map(), indent=2, ensure_ascii=False))
    except Exception as error:
        # å¤±è´¥ï¼šæ‰“å°é”™è¯¯ä¿¡æ¯å’Œé˜¿é‡Œäº‘æ•…éšœæ’æŸ¥é“¾æ¥
        print(error.message)
        print(error.data.get("Recommend"))
        raise   # å‘ä¸ŠæŠ›å‡ºï¼Œè®© GitHub Actions çœ‹åˆ°å¤±è´¥


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å‡½æ•°å››ï¼šé€šè¿‡èŠ‚ç‚¹åç²¾ç¡®æŸ¥æ‰¾ï¼Œè¿”å›æ•°æ®å¼€å‘èŠ‚ç‚¹ ID (Data Studio Node ID)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_node_id(client: DataWorksPublicClient, project_id: int, node_name: str) -> int:
    """
    é€šè¿‡èŠ‚ç‚¹ååœ¨ DataWorks å·¥ä½œç©ºé—´ä¸­ç²¾ç¡®æŸ¥æ‰¾èŠ‚ç‚¹ã€‚

    ä½¿ç”¨ ListFiles API çš„ ExactFileName å‚æ•°åšç²¾ç¡®åŒ¹é…ï¼ˆéæ¨¡ç³Šæœç´¢ï¼‰ã€‚
    æ³¨æ„ï¼šåœ¨ DataWorks 2024-05-18 OpenAPI ä¸­ï¼Œæ•°æ®å¼€å‘ï¼ˆData Studioï¼‰ä¸­çš„èŠ‚ç‚¹ï¼ˆNodeï¼‰
    å…¶å”¯ä¸€æ ‡è¯†å¯¹åº”çš„æ˜¯ ListFiles æ¥å£è¿”å›çš„ file_idï¼ˆè€Œè¿”å›çš„ node_id æ˜¯å‘å¸ƒåè°ƒåº¦ç³»ç»Ÿçš„ IDï¼‰ã€‚
    UpdateNode å’Œ GetNode æ¥å£éœ€è¦çš„ id å‚æ•°å‡ä¸ºè¿™ä¸ªæ•°æ®å¼€å‘èŠ‚ç‚¹ IDï¼ˆfile_idï¼‰ã€‚

    Args:
        client:     ç”± create_client() è¿”å›çš„ SDK å®¢æˆ·ç«¯
        project_id: DataWorks å·¥ä½œç©ºé—´ ID
        node_name:  ç²¾ç¡®èŠ‚ç‚¹åç§°ï¼ˆä¸ task-config.json ä¸­çš„ node_name ä¸€è‡´ï¼‰
    Returns:
        èŠ‚ç‚¹ IDï¼ˆintï¼‰ï¼›æœªæ‰¾åˆ°æ—¶è¿”å› None
    """
    print(f"ğŸ” Checking if node '{node_name}' exists in project {project_id}...")
    request = dw_models.ListFilesRequest(
        project_id=project_id,
        exact_file_name=node_name,
        page_size=10,
    )
    try:
        resp = client.list_files_with_options(request, util_models.RuntimeOptions())
        files = (
            resp.body.data.files
            if (resp.body and resp.body.data and resp.body.data.files)
            else []
        )
    except Exception as error:
        msg = error.message if hasattr(error, "message") else str(error)
        print(f"   ListFiles failed: {msg}")
        return None

    if not files:
        print(f"   Node '{node_name}' not found.")
        return None

    f = files[0]
    # Data Studio èŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†åœ¨ ListFiles é‡Œå¯¹åº” file_id
    ds_node_id = f.file_id
    print(f"   Found â€” DataStudio NodeId={ds_node_id} (Scheduled NodeId={f.node_id})")
    return ds_node_id


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¾…åŠ©å‡½æ•°ï¼šé€šè¿‡ GetNode æ‹‰å–è¿œç«¯èŠ‚ç‚¹å½“å‰çš„ Spec
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _get_remote_spec(client: DataWorksPublicClient, project_id: int, node_id: int) -> dict:
    """
    è°ƒç”¨ GetNode API è·å–è¿œç«¯èŠ‚ç‚¹çš„å®Œæ•´ FlowSpecï¼Œè§£æåè¿”å› dictã€‚
    è·å–å¤±è´¥æ—¶è¿”å›ç©º dictï¼ˆä¸ä¸­æ–­ä¸»æµç¨‹ï¼‰ã€‚
    """
    try:
        request = dw_models.GetNodeRequest(project_id=project_id, id=node_id)
        resp = client.get_node_with_options(request, util_models.RuntimeOptions())
        node = resp.body.node
        if node and node.spec:
            return json.loads(node.spec)
    except Exception as error:
        msg = error.message if hasattr(error, "message") else str(error)
        print(f"   âš ï¸  GetNode failed (diff skipped): {msg}")
    return {}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¾…åŠ©å‡½æ•°ï¼šé€’å½’æ‰å¹³åŒ– dictï¼Œç”Ÿæˆ "a.b.c" â†’ value æ˜ å°„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _flatten(d, prefix=""):
    """
    å°†åµŒå¥— dict/list é€’å½’å±•å¼€ä¸ºæ‰å¹³çš„ keyâ†’value å­—å…¸ï¼Œæ–¹ä¾¿é€å­—æ®µå¯¹æ¯”ã€‚

    ä¾‹å¦‚ï¼š{"spec": {"nodes": [{"name": "foo"}]}}
    å±•å¼€ä¸ºï¼š{"spec.nodes[0].name": "foo"}
    """
    items = {}
    if isinstance(d, dict):
        for k, v in d.items():
            full_key = f"{prefix}.{k}" if prefix else k
            items.update(_flatten(v, full_key))
    elif isinstance(d, list):
        for i, v in enumerate(d):
            items.update(_flatten(v, f"{prefix}[{i}]"))
    else:
        items[prefix] = d
    return items


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¾…åŠ©å‡½æ•°ï¼šæ¯”å¯¹æœ¬åœ°ä¸è¿œç«¯ Specï¼Œæ‰“å°å·®å¼‚
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _print_diff(local_spec: dict, remote_spec: dict) -> int:
    """
    å°†æœ¬åœ° Spec ä¸è¿œç«¯ Spec æ‰å¹³åŒ–ååšå­—æ®µçº§æ¯”å¯¹ï¼Œæ‰“å°æ‰€æœ‰æœ‰å·®å¼‚çš„å­—æ®µã€‚

    Returns:
        diff_count: å·®å¼‚å­—æ®µæ•°é‡ï¼ˆ0 è¡¨ç¤ºæ— å·®å¼‚ï¼‰
    """
    if not remote_spec:
        print("   (Remote spec unavailable, skipping diff)")
        return -1   # -1 è¡¨ç¤ºæ— æ³•åˆ¤æ–­

    local_flat  = _flatten(local_spec)
    remote_flat = _flatten(remote_spec)

    all_keys = set(local_flat) | set(remote_flat)
    diffs = []

    for key in sorted(all_keys):
        local_val  = local_flat.get(key, "<missing>")
        remote_val = remote_flat.get(key, "<missing>")

        # content å­—æ®µæ˜¯åµŒå¥—çš„ JSON å­—ç¬¦ä¸²ï¼Œéœ€è¦è¿›ä¸€æ­¥è§£æåæ¯”å¯¹
        if key.endswith(".content") and isinstance(local_val, str) and isinstance(remote_val, str):
            try:
                local_inner  = json.loads(local_val)
                remote_inner = json.loads(remote_val)
                inner_diffs = _flatten(local_inner)
                inner_remote = _flatten(remote_inner)
                for ik in sorted(set(inner_diffs) | set(inner_remote)):
                    iv  = inner_diffs.get(ik,  "<missing>")
                    irv = inner_remote.get(ik, "<missing>")
                    if iv != irv:
                        diffs.append((f"{key} â†’ {ik}", irv, iv))
                continue   # è·³è¿‡åŸå§‹å­—ç¬¦ä¸²æ¯”å¯¹
            except (json.JSONDecodeError, TypeError):
                pass   # è§£æå¤±è´¥åˆ™é™çº§ä¸ºå­—ç¬¦ä¸²æ¯”å¯¹

        if local_val != remote_val:
            diffs.append((key, remote_val, local_val))

    if not diffs:
        print("   âœ… No differences detected. Node is already up to date.")
        return 0

    print(f"   ğŸ“‹ Found {len(diffs)} field(s) with differences:\n")
    col_w = max(len(d[0]) for d in diffs) + 2
    print(f"   {'Field':<{col_w}}  {'Remote (current)':<40}  {'Local (new)'}")
    print(f"   {'-'*col_w}  {'-'*40}  {'-'*40}")
    for field, old_val, new_val in diffs:
        old_str = str(old_val)[:38] + ".." if len(str(old_val)) > 40 else str(old_val)
        new_str = str(new_val)[:38] + ".." if len(str(new_val)) > 40 else str(new_val)
        print(f"   {field:<{col_w}}  {old_str:<40}  {new_str}")
    print()
    return len(diffs)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å‡½æ•°äº”ï¼šå¢é‡æ›´æ–°å·²æœ‰èŠ‚ç‚¹ï¼ˆå« diff è¾“å‡ºï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def update_node(client: DataWorksPublicClient, project_id: int, node_id: int, config: dict) -> None:
    """
    è°ƒç”¨ DataWorks UpdateNode APIï¼Œä»¥å¢é‡æ–¹å¼æ›´æ–°èŠ‚ç‚¹é…ç½®ã€‚
    æ›´æ–°å‰ä¼šæ‹‰å–è¿œç«¯å½“å‰ Specï¼Œæ‰“å°å­—æ®µçº§ diffï¼Œæœ‰å·®å¼‚æ‰æ‰§è¡Œæ›´æ–°ã€‚

    Args:
        client:     ç”± create_client() è¿”å›çš„ SDK å®¢æˆ·ç«¯
        project_id: DataWorks å·¥ä½œç©ºé—´ IDï¼ˆGetNode éœ€è¦ï¼‰
        node_id:    ç”± get_node_id() è¿”å›çš„ NodeId
        config:     ç”± task-config.json è¯»å–çš„é…ç½®å­—å…¸
    """
    local_spec  = json.loads(build_spec(config))
    remote_spec = _get_remote_spec(client, project_id, node_id)

    print("\n   ğŸ” Comparing local config with remote node spec...")
    diff_count = _print_diff(local_spec, remote_spec)

    if diff_count == 0:
        print("   Skipping update â€” nothing changed.")
        return

    # æœ‰å·®å¼‚ï¼ˆæˆ–æ— æ³•æ‹‰å–è¿œç«¯ï¼‰åˆ™æ‰§è¡Œæ›´æ–°
    update_request = dw_models.UpdateNodeRequest(
        project_id=project_id,
        id=node_id,
        spec=json.dumps(local_spec, ensure_ascii=False)
    )
    runtime = util_models.RuntimeOptions()

    try:
        resp = client.update_node_with_options(update_request, runtime)
        if resp.body.success:
            print(f"   âœ… Node updated successfully. (NodeId={node_id})")
        else:
            print(f"   âŒ UpdateNode returned success=False. RequestId={resp.body.request_id}")
            raise RuntimeError("UpdateNode returned success=False")
    except Exception as error:
        msg = error.message if hasattr(error, "message") else str(error)
        print(f"   âŒ UpdateNode failed: {msg}")
        if hasattr(error, "data") and error.data:
            print(error.data.get("Recommend", ""))
        raise
