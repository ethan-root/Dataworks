"""
deploy.py ‚Äî ‰∏ªÂÖ•Âè£
ÊéßÂà∂ DataWorks ÂàõÂª∫ÂÆöÊó∂‰ªªÂä°ÁöÑ CLI ÂÖ•Âè£
ÊîØÊåÅÂÖ®ÈáèÈÉ®ÁΩ≤„ÄÅÊåáÂÆöÈ°πÁõÆÈÉ®ÁΩ≤„ÄÅÂàÜÊ≠•ÊµãËØïÊâßË°å

Áî®Ê≥ï:
    python scripts/deploy.py                                          # Â§ÑÁêÜÊâÄÊúâÈ°πÁõÆ
    python scripts/deploy.py --projects Gucci                         # ÊåáÂÆöÈ°πÁõÆ
    python scripts/deploy.py --projects Gucci,Balenciaga              # Â§ö‰∏™È°πÁõÆ
    python scripts/deploy.py --project-dir projects/Test --step check_cli      # ÊµãËØï CLI ËøûÊé•
    python scripts/deploy.py --project-dir projects/Test --step check_datasources
    python scripts/deploy.py --project-dir projects/Test --step create_job
    python scripts/deploy.py --project-dir projects/Test --step submit --file-id 12345
    python scripts/deploy.py --project-dir projects/Test --step deploy --file-id 12345

ÁéØÂ¢ÉÂèòÈáè:
    ALIBABA_CLOUD_ACCESS_KEY_ID     ÈòøÈáå‰∫ë AK ID
    ALIBABA_CLOUD_ACCESS_KEY_SECRET ÈòøÈáå‰∫ë AK Secret
    ALIYUN_REGION                   Âå∫Âüü (Â¶Ç cn-shanghai)
    DATAWORKS_PROJECT_ID            DataWorks Â∑•‰ΩúÁ©∫Èó¥ ID
"""

import argparse
import json
import logging
import os
import sys
from pathlib import Path

# Â∞Ü scripts/ ÁõÆÂΩïÂä†ÂÖ• sys.pathÔºå‰ª•‰æøÂØºÂÖ•ÂêåÁõÆÂΩïÊ®°Âùó
SCRIPT_DIR = Path(__file__).resolve().parent
sys.path.insert(0, str(SCRIPT_DIR))

from dataworks_client import DataWorksClient
from process_project import process_project

# ---- Êó•ÂøóÈÖçÁΩÆ ----
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


def get_env_or_fail(name: str) -> str:
    """Ëé∑ÂèñÂøÖÈ°ªÁöÑÁéØÂ¢ÉÂèòÈáè"""
    value = os.environ.get(name, "").strip()
    if not value:
        logger.error(f"Environment variable '{name}' is required but not set.")
        sys.exit(1)
    return value


def create_client() -> DataWorksClient:
    """‰ªéÁéØÂ¢ÉÂèòÈáèÂàõÂª∫ DataWorksClient"""
    return DataWorksClient(
        access_key_id=get_env_or_fail("ALIBABA_CLOUD_ACCESS_KEY_ID"),
        access_key_secret=get_env_or_fail("ALIBABA_CLOUD_ACCESS_KEY_SECRET"),
        region=get_env_or_fail("ALIYUN_REGION"),
        project_id=int(get_env_or_fail("DATAWORKS_PROJECT_ID")),
    )


# =========================================================================
# ÂàÜÊ≠•ÊµãËØïÂëΩ‰ª§
# =========================================================================

def step_check_cli(client: DataWorksClient):
    """Step 1: È™åËØÅ SDK ËøûÊé•"""
    logger.info("=" * 60)
    logger.info("Testing DataWorks SDK connection ...")
    logger.info("=" * 60)
    groups = client.list_resource_groups()
    logger.info(f"‚úÖ Connection successful! Found {len(groups)} resource group(s).")
    for g in groups:
        logger.info(f"  Identifier: {g.identifier}")


def step_check_datasources(client: DataWorksClient, project_dir: str):
    """Step 3: Ê£ÄÊü•Êï∞ÊçÆÊ∫êÊòØÂê¶Â≠òÂú®"""
    config = _load_config(project_dir)
    oss_ds = config["OSS"]["DataSourceName"]
    odps_ds = config["MaxCompute"]["DataSourceName"]

    logger.info("=" * 60)
    logger.info("Checking DataSources ...")
    logger.info("=" * 60)

    oss_exists = client.datasource_exists(oss_ds)
    odps_exists = client.datasource_exists(odps_ds)

    logger.info(f"  OSS '{oss_ds}': {'‚úÖ EXISTS' if oss_exists else '‚ùå NOT FOUND'}")
    logger.info(f"  MaxCompute '{odps_ds}': {'‚úÖ EXISTS' if odps_exists else '‚ùå NOT FOUND'}")


def step_create_oss_ds(client: DataWorksClient, project_dir: str):
    """Step 4: ÂàõÂª∫ OSS Êï∞ÊçÆÊ∫ê"""
    config = _load_config(project_dir)
    client.ensure_oss_datasource(config)


def step_create_odps_ds(client: DataWorksClient, project_dir: str):
    """Step 5: ÂàõÂª∫ MaxCompute Êï∞ÊçÆÊ∫ê"""
    config = _load_config(project_dir)
    client.ensure_odps_datasource(config)


def step_create_job(client: DataWorksClient, project_dir: str):
    """Step 6: ÂàõÂª∫ÂêåÊ≠• Job"""
    config = _load_config(project_dir)
    project_name = config["ProjectName"]
    table_name = config["Tables"][0]["Name"]
    job_name = f"{project_name}_{table_name}"

    logger.info("=" * 60)
    logger.info(f"Creating DI Sync Task: {job_name}")
    logger.info("=" * 60)

    task_content = client.generate_task_content(config, 0)
    logger.info(f"TaskContent:\n{json.dumps(task_content, indent=2)}")

    resource_group = config["ResourceGroupIdentifier"]
    file_id = client.create_sync_task(job_name, task_content, resource_group)
    logger.info(f"‚úÖ Task created! FileId = {file_id}")
    logger.info(f"üìù Use --file-id {file_id} for submit/deploy steps")

    # ËæìÂá∫ FileId ‰æõ GitHub Actions ‰ΩøÁî®
    github_output = os.environ.get("GITHUB_OUTPUT")
    if github_output:
        with open(github_output, "a") as f:
            f.write(f"file_id={file_id}\n")


def step_submit(client: DataWorksClient, file_id: int):
    """Step 7: Êèê‰∫§‰ªªÂä°"""
    logger.info("=" * 60)
    logger.info(f"Submitting FileId: {file_id}")
    logger.info("=" * 60)
    client.submit_file(file_id)
    logger.info("‚úÖ File submitted successfully.")


def step_deploy(client: DataWorksClient, file_id: int):
    """Step 8: ÂèëÂ∏ÉÂà∞Áîü‰∫ß"""
    logger.info("=" * 60)
    logger.info(f"Deploying FileId: {file_id}")
    logger.info("=" * 60)
    client.deploy_file(file_id)
    logger.info("‚úÖ File deployed to production.")


# =========================================================================
# ÂÖ®ÈáèÈÉ®ÁΩ≤
# =========================================================================

def deploy_all(client: DataWorksClient, projects_dir: str, target_projects: str = ""):
    """ÈÅçÂéÜÈ°πÁõÆÁõÆÂΩïÔºåÈÄê‰∏ÄÂ§ÑÁêÜ"""
    projects_path = Path(projects_dir)

    logger.info("")
    logger.info("‚ïî" + "‚ïê" * 60 + "‚ïó")
    logger.info("‚ïë   DataWorks Data Integration ‚Äî Deployment Tool            ‚ïë")
    logger.info("‚ï†" + "‚ïê" * 60 + "‚ï£")
    logger.info(f"‚ïë  Project ID: {client.project_id}")
    logger.info(f"‚ïë  Projects Dir: {projects_path}")
    logger.info(f"‚ïë  Target: {target_projects or 'ALL'}")
    logger.info("‚ïö" + "‚ïê" * 60 + "‚ïù")

    # ÊûÑÂª∫È°πÁõÆÂàóË°®
    project_dirs = []
    if target_projects:
        for name in target_projects.split(","):
            name = name.strip()
            d = projects_path / name
            if not d.is_dir():
                logger.error(f"Project directory not found: {d}")
                sys.exit(1)
            project_dirs.append(str(d))
    else:
        for d in sorted(projects_path.iterdir()):
            if d.is_dir() and (d / "config.json").exists():
                project_dirs.append(str(d))

    if not project_dirs:
        logger.error(f"No project directories found in {projects_path}")
        sys.exit(1)

    logger.info(f"Found {len(project_dirs)} project(s) to process.")

    total_success = 0
    total_failed = 0

    for project_dir in project_dirs:
        stats = process_project(client, project_dir)
        if stats["failed"] > 0:
            total_failed += 1
        else:
            total_success += 1

    logger.info("")
    logger.info("‚ïî" + "‚ïê" * 60 + "‚ïó")
    logger.info("‚ïë                  Deployment Complete                       ‚ïë")
    logger.info("‚ï†" + "‚ïê" * 60 + "‚ï£")
    logger.info(f"‚ïë  Projects Succeeded: {total_success}")
    logger.info(f"‚ïë  Projects Failed:    {total_failed}")
    logger.info("‚ïö" + "‚ïê" * 60 + "‚ïù")

    if total_failed > 0:
        logger.error("Some projects failed. Check the logs above.")
        sys.exit(1)

    logger.info("All projects deployed successfully!")


# =========================================================================
# Helper
# =========================================================================

def _load_config(project_dir: str) -> dict:
    """Âä†ËΩΩ config.json"""
    config_path = Path(project_dir) / "config.json"
    if not config_path.exists():
        logger.error(f"config.json not found in {project_dir}")
        sys.exit(1)
    with open(config_path, "r", encoding="utf-8") as f:
        return json.load(f)


# =========================================================================
# CLI
# =========================================================================

def main():
    parser = argparse.ArgumentParser(description="DataWorks Data Integration Deployment Tool")

    parser.add_argument("--projects", type=str, default="",
                        help="Comma-separated project names (default: all)")
    parser.add_argument("--projects-dir", type=str, default="projects",
                        help="Projects root directory (default: projects)")
    parser.add_argument("--project-dir", type=str, default="",
                        help="Single project directory for step execution")
    parser.add_argument("--step", type=str, default="",
                        choices=["", "check_cli", "check_datasources",
                                 "create_oss_ds", "create_odps_ds",
                                 "create_job", "submit", "deploy"],
                        help="Execute a single step (for testing)")
    parser.add_argument("--file-id", type=int, default=0,
                        help="FileId for submit/deploy steps")

    args = parser.parse_args()

    client = create_client()

    if args.step:
        # ---- ÂàÜÊ≠•ÊâßË°å ----
        if args.step == "check_cli":
            step_check_cli(client)
        elif args.step == "check_datasources":
            step_check_datasources(client, args.project_dir or "projects/Test")
        elif args.step == "create_oss_ds":
            step_create_oss_ds(client, args.project_dir or "projects/Test")
        elif args.step == "create_odps_ds":
            step_create_odps_ds(client, args.project_dir or "projects/Test")
        elif args.step == "create_job":
            step_create_job(client, args.project_dir or "projects/Test")
        elif args.step == "submit":
            if not args.file_id:
                logger.error("--file-id is required for submit step")
                sys.exit(1)
            step_submit(client, args.file_id)
        elif args.step == "deploy":
            if not args.file_id:
                logger.error("--file-id is required for deploy step")
                sys.exit(1)
            step_deploy(client, args.file_id)
    else:
        # ---- ÂÖ®ÈáèÈÉ®ÁΩ≤ ----
        deploy_all(client, args.projects_dir, args.projects)


if __name__ == "__main__":
    main()
